\documentclass{beamer}
%
% Choose how your presentation looks.
%
% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\mode<presentation>
{
  %\usetheme{Ilmenau}
  \usetheme{default}      % or try Darmstadt, Madrid, Warsaw, ...
  \usecolortheme{default} % or try albatross, beaver, crane, ...
  \usefonttheme{default}  % or try serif, structurebold, ...
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
} 

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{pstricks}
\usepackage{tikz}
\usetikzlibrary{positioning, shapes, shapes.geometric, arrows}

% These two lines are required to fix font issue.
% Track here: https://tex.stackexchange.com/questions/133781/font-display-error-in-windows
\usepackage{sansmathaccent}
\pdfmapfile{+sansmathaccent.map}

\tikzstyle{block1} = [rectangle, draw, fill=blue!20, text centered, rounded corners]
\tikzstyle{block2} = [rectangle, draw, fill=red!20, text centered, rounded corners]
\tikzstyle{block3} = [rectangle, draw, text centered]
\tikzstyle{arrow} = [thick,->,>=stealth]

\title{
  \textbf{Business Analytics in R} \\
  Introduction to Statistical Programming
}
% \author{
%   Timothy Wong\thanks{\url{timothy.wong@hotmail.co.uk}} \\
%   James Gammerman\thanks{\url{jgammerman@gmail.com}}
% }

<<setup, include=FALSE>>=
library(checkpoint)
checkpoint(snapshotDate = '2018-08-01', 
           auto.install.knitr = TRUE, 
           scan.rnw.with.knitr = TRUE, 
           verbose = TRUE,
           use.knitr = TRUE,
           scanForPackages = TRUE,
           checkpointLocation=getwd())
@

\defbeamertemplate*{section page}{ifttheme}%[1][]
{\vbox{}\vskip-3.2cm%
\begin{beamercolorbox}[sep=0.3cm,ht=0.5\paperheight,wd=\paperwidth]{red}
    \begin{center}
        \begin{minipage}[c]{0.55\paperwidth}
        \centering \Huge \insertsection%\par
        \end{minipage}
    \end{center}
\end{beamercolorbox}
}

\AtBeginSection[]{\frame{\sectionpage}}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}[shrink]{Outline}
    \tableofcontents
\end{frame}

\section{R Ecosystem}

\begin{frame}{What is the R language?}
  \begin{itemize}
    \item Offers modern and sophisticated statistical algorithms
    \item Used by millions of analysts and researchers worldwide
    \item Has a thriving open-source community
    \item Enables big data analytics
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Easy to Use}
  \begin{itemize}
    \item \verb|PROC REG| 	= \verb|lm()| or \verb|glm()|
    \item \verb|PROC SQL| 	= \verb|%>%|
    \item \verb|PROC SORT| 	= \verb|arrange()|
    \item \verb|PROC MEANS|	= \verb|mean()|, \verb|sd()|
    \item \verb|PROC GPLOT|	= \verb|plot()|, \verb|ggplot()|, \verb|autoplot()|
  \end{itemize}
\end{frame}


\begin{frame}[fragile]{RStudio Server Pro}
  \begin{itemize}
    \item RStudio is your integrated development environment (IDE)
  \end{itemize}
  \includegraphics[width=\textwidth]{img/rstudio.PNG}
\end{frame}


\begin{frame}[fragile, shrink]{Packages}
\begin{itemize}
  \item \textbf{CRAN} is the Comprehensive R Archive Network.
  \item User-contributed packages: source code, binaries, documentation.
\end{itemize}
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Return all installed packages
installed.packages()
# Install a new package and all its dependencies from CRAN
# This will install to the default library location
install.packages("ggplot2")
# Load an installed package 
# (both lines are identical)
library(ggplot2)
library("ggplot2")
@
\end{frame}

\begin{frame}[fragile, shrink]{Packages}
\begin{itemize}
  \item \textbf{CRAN Task View} is a curated list of packages.
  \item Useful guide to get started with \verb|R|.
  \item \url{https://cran.r-project.org/web/views/}
\end{itemize}
\end{frame}


\begin{frame}[fragile, shrink]{Variable Assignment}
\begin{itemize}
  \item Assign variables using the \verb|<-| symbol.
  \item Do not use reserved words. This will confuse the interpreter.
\end{itemize}
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Assign variables
myVarX <- 5
myVarY <- 20
# Perform multiplication
myVarX * myVarY
# Look at the reserved words
?Reserved
# Camal case
myCamalCaseVar <- "this is camal case"
# Other less commonly-used styles
my_snake_case_var <- "this is lower snake case"
MY_UPPER_SNAKE_CASE_VAR <- "this is upper snake case"
my.dot.case.var <- "this is dot case"
MyPascalCaseVar <- "this is pascal case"
@
\end{frame}


\begin{frame}[fragile, shrink]{Vectors}
\begin{itemize}
  \item R is a vectorised programming language.
  \item Vector contains elements of the same data type.
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myVec1 <- 1:10
# Find out the length of vector
length(myVec1)
# Reverse the vector
# This does not change the value of myVec1
rev(myVec1)
# Create a custom vector of 10, 15, 20, 25, 30
myVec2 <- c(10, 15, 20, 25, 30)
myVec2
# Create a vector of sequential numbers with increment 0.5
myVec3 <- seq(from = -2, to = 2, by = 0.5)
myVec3
# Elements of a vector can be named
myVec4 <- c(`New York` = 8.5,
            `London` = 8.6,
            `Moscow` = 11.9)
myVec4
@
\end{frame}


\begin{frame}[fragile]{Subsetting a Vector}
\begin{itemize}
  \item You can subset elements from a vector.
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Select the second element of the vector
myVec2[2]
# Subset a range from the vector
myVec2[2:4]
# Subset specified elements
myVec2[c(4,2,3)]
# Subset named element of a vector
myVec4["New York"]
@
\end{frame}

\begin{frame}[fragile, shrink]{Vectorised Operations}
\begin{itemize}
  \item Operations in R are vectorised.
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Arithmetic operations
myVec1 + 10
myVec1 - 10
myVec1 * 2
myVec1 / 2
myVec1 ^ 2
log(myVec1)
@
\end{frame}

\begin{frame}[fragile, shrink]{Character Vectors}
\begin{itemize}
  \item Vector can also contain character objects.
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Vector can contain character objects
myVec4 <- c("Bill", "Mark", "Steve", "Jeff", "Larry")
myVec4
# Constant character vectors in R
LETTERS
letters
month.name
month.abb
@
\end{frame}


\begin{frame}[fragile, shrink]{Date and Date/Time Vectors}
\begin{itemize}
  \item \verb|Date| is a data type in base \verb|R|.
  \item The package \verb|lubridate| extends date/time functionalities.
  \item Enables easier date/time manipulation.
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# This is a vector of Date objects
myVec5 <- as.Date(c("2017-07-13",
                    "2017-10-11",
                    "2017-11-21",
                    "2018-01-16", 
                    "2018-03-27"))
# Load the lubridate package
# Use the function ymd_hms() to parse date/time with timezone
# Returns a vector of POSIXct (date/time) object
library(lubridate)
myVec6 <- ymd_hms(c("2017-07-13 09:30:00",
                    "2017-10-11 08:00:00",
                    "2017-11-21 10:00:00",
                    "2018-01-16 11:30:00", 
                    "2018-03-27 12:00:00"),
                  tz = "Europe/London")
# Date/time manipulation applied to a vector
myVec7 <- myVec6 + hours(1) + minutes(30)
# Compute the day of week - returns a vector of characters
weekdays(myVec7)
@
\end{frame}




\begin{frame}[fragile, shrink]{Logical Operators}
\begin{itemize}
  \item Apply logical operators on vector objects.
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Find all values greater than 5 - returns a vector of logical values 
myVec1 > 5
# Find all values equal to 7
myVec1 == 7
# Find all values matching 2,4,6 and 8
myVec1 %in% c(2,4,6,8)
# Find all values between 2 and 7
myVec1 >= 2 & myVec1 <= 7
# Find all values equal to 7 or equal to 8
myVec1 == 7 | myVec1 == 8
@
\end{frame}


\begin{frame}[fragile, shrink]{Special Numbers in R}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Pi is constant 3.14159...
pi
# One divided by zero is infinity
1/0
# Negative number divided by zero is negative infinity
-1/0
# Infinity divided by infinity is Not-a-Number (NaN)
Inf/Inf
# Not available (NA) plus one is still NA
NA + 1
# Effects of different special numbers
c(5, 10, 15, NA, 25, 30, NaN, 35, 40, Inf, 50, -Inf, 60) / 5
@
\end{frame}




\begin{frame}[fragile, shrink]{List}
\begin{itemize}
  \item List is a generic container for objects of different data types
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myFavBook <- list(title = "R for Data Science",
                  authors = c("Garrett Grolemund", "Hadley Wickham"),
                  publishDate = as.Date("2016-12-12"),
                  price = 18.17,
                  currency = "USD",
                  edition = 1,
                  isbn = 1491910399)
myFavBook
@
\end{frame}


\begin{frame}[fragile, shrink]{Subsetting a List}
\begin{itemize}
  \item You can subset a particular member from a list
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Select a named element of a list
# Use the dollar sign, followed by name without bracket
myFavBook$title
# Use double squared brackets with element's name as character
myFavBook[["authors"]]
# Select the fourth element in the list
myFavBook[[4]]
@
\end{frame}





\begin{frame}[fragile, shrink]{Data Frame}
\begin{itemize}
  \item Table with rows (observations) and columns (variables).
  \item Analogous to an Excel workbook.
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myFavMovies1 <- data.frame(title = c("Dr. No",
                                     "Goldfinger",
                                     "Diamonds are Forever",
                                     "Moonraker",
                                     "The Living Daylights",
                                     "GoldenEye",
                                     "Casino Royale"),
                           year = c(1962, 1964, 1971, 1979, 
                                    1987, 1995, 2006),
                           box = c(59.5, 125, 120, 210.3,
                                   191.2, 355, 599),
                           bondActor = c("Sean Connery",
                                         "Sean Connery",
                                         "Sean Connery",
                                         "Roger Moore",
                                         "Timothy Dalton",
                                         "Pierce Brosnan",
                                         "Daniel Craig"))
@
\end{frame}

\begin{frame}[fragile, shrink]{Data Frame}
<<fig.show='asis', results=TRUE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE>>=
myFavMovies1
@
\end{frame}

\begin{frame}[fragile, shrink]{Tibble}
\begin{itemize}
  \item Similar to traditional \verb|data frame|.
  \item \verb|tibble| is the modern standard in R.
\end{itemize}
<<fig.show='hide', eval=TRUE, results='hide', warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
library(tibble)
myFavMovies2 <- tibble(title = c("Dr. No",
                                 "Goldfinger",
                                 "Diamonds are Forever",
                                 "Moonraker",
                                 "The Living Daylights",
                                 "GoldenEye",
                                 "Casino Royale"),
                       year = c(1962, 1964, 1971, 1979, 
                                1987, 1995, 2006),
                       box = c(59.5, 125, 120, 210.3,
                               191.2, 355, 599),
                       bondActor = c("Sean Connery",
                                     "Sean Connery",
                                     "Sean Connery",
                                     "Roger Moore",
                                     "Timothy Dalton",
                                     "Pierce Brosnan",
                                     "Daniel Craig"))
# Append an extra row at the end of the tibble
# Rewrite the original tibble object
myFavMovies2 <- add_row(myFavMovies2, 
        title = "Spectre", year = 2015, box = 880.7,
        bondActor = "Daniel Craig")
@
\end{frame}

\begin{frame}[fragile, shrink]{Tibble}
<<fig.show='asis', results=TRUE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE>>=
myFavMovies2
@
\end{frame}

\begin{frame}[fragile, shrink]{Subsetting a Tibble}
<<fig.show='asis', results=TRUE, eval=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
# Get one column by name
myFavMovies2[["title"]]
myFavMovies2$title
# Get a range of columns by position ID
myFavMovies2[, 1:2]
myFavMovies2[1:2]
# Get rows 1 to 3
myFavMovies2[1:3, ]
# Get the "year" variable of row 1-3 
myFavMovies2[1:3, "year"]
# Get the "title" and "year" variables of row 4-7 
myFavMovies2[4:7, c("title","year")]
@
\end{frame}

\begin{frame}[fragile, shrink]{Functions}
\begin{itemize}
  \item Functions are vectorised.
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
is.odd <- function(x) {
  # The modulo operator %% returns the remainder
  # If a number divide by 2 gives remainder 1, then it is an odd number
  remainder <- x %% 2
  equalToOne <- remainder == 1
  return(equalToOne)
}
# Execute the function with one input
is.odd(5)
# Execute the function with an integer vector
is.odd(1:10)
# Define another function
is.even <- function(x) {
  !is.odd(x)
}
# Return true for even numbers
is.even(1:10)
@
\end{frame}



\begin{frame}[fragile, shrink]{If-Else}
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
library(lubridate)
# Find out what day is today
myWeekday <- weekdays(today())
# Check whether today is Saturday or Sunday
if (myWeekday %in% c("Saturday","Sunday")) {
  myGreeting <- "Have a nice weekend"
} else {
  myGreeting <- "Go back to work"
}
# Prints the message
myGreeting
@
\end{frame}


\begin{frame}[fragile, shrink]{If-Else}
\begin{itemize}
  \item Multiple conditions are allowed.
\end{itemize}
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
library(lubridate)
myWeekday <- weekdays(today())
# Checks multiple conditions
if (myWeekday %in% c("Saturday","Sunday")) {
  myGreeting <- "Have a nice weekend"
} else if(myWeekday == "Friday"){
  myGreeting <- "It's Friday!"
} else if(myWeekday == "Monday"){
  myGreeting <- "Oh no..."
} else {
  myGreeting <- "Go back to work"
}
myGreeting
@
\end{frame}



\begin{frame}[fragile, shrink]{While}
\begin{itemize}
  \item Loops as long the condition stays \verb|TRUE|.
\end{itemize}
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myCounter <- 100
while (myCounter > 0) {
  myCounter <- myCounter - 5
  print(myCounter)
}
@
\end{frame}


\begin{frame}[fragile, shrink]{While}
\begin{itemize}
  \item Skip an iteration using \verb|next|
  \item Early exit using \verb|break|
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myCounter <- 100
while (myCounter > 0) {
  myCounter <- myCounter - 5
  if (myCounter > 50) {
    # Skips all iterations if the counter value is greater than 50
    next
  }
  if (myCounter == 10) {
    # Early stop if the counter value matches 10
    break
  }
  print(myCounter)
}
@
\end{frame}


\begin{frame}[fragile, shrink]{For}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myResult <- 0
for (i in 1:100) {
  myResult <- myResult + i ^ 2
}
myResult
@
\end{frame}



\begin{frame}[fragile, shrink]{Apply}
\begin{itemize}
  \item \verb|apply()| takes a 'grid' input: \verb|data frame|, \verb|tibble|, or \verb|matrix|
  \item Margin 1 = apply over rows
  \item Margin 2 = apply over columns
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# The second argument 1 inidicates iterate over rows
myMessages1 <- apply(myFavMovies2, 1, function(row){ 
  sprintf("%s was released in %s.", row["title"], row["year"])
})
myMessages1
@
\end{frame}


\begin{frame}[fragile, shrink]{lapply}
\begin{itemize}
  \item \verb|lapply()| always returns a list
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# The second argument 1 inidicates iterate over rows
myMessages2 <- lapply(myFavMovies2$title, 
                      function(x){ sprintf("%s is a great movie!", x) })
# Checks the data type of the result
typeof(myMessages2)
# Check whether it is a list
is.list(myMessages2)
# Select the 6th element of the list
myMessages2[[6]]
@
\end{frame}


\begin{frame}[fragile, shrink]{sapply}
\begin{itemize}
  \item \verb|sapply()| always returns a vector
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myMessages3 <- sapply(myFavMovies2$title, 
                      function(x){ sprintf("%s is a great movie!", x) })
# Check whether it is a list
is.list(myMessages3)
myMessages3
@
\end{frame}


\begin{frame}[fragile, shrink]{Looping}
\begin{itemize}
  \item Looping can be slow.
  \item Always try to vectorise your code.
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize', cache=TRUE>>=
# Vectorised operation is fast
system.time({
  myResult <- 1:100000 * 2
})
# Looping is quite slow
system.time({
  myResult <- sapply(1:100000, function(x){ x * 2 })
})
# Appending to vector is much slower
system.time({
  myResult <- c()
  for(i in 1:100000){
    myResult <- c(myResult, i * 2)
  }
})
@
\end{frame}


\begin{frame} [fragile, shrink] {UK User Communities}
\begin{itemize}
  \item LondonR - \includegraphics[width=0.2\textwidth]{img/londonr.PNG}
  \item ManchesterR - \includegraphics[width=0.2\textwidth]{img/manchesterr.png}
  \item CaRdiff - \includegraphics[width=0.2\textwidth]{img/cardiff.JPG}
  \item SheffieldR
  \item EdinbR - \includegraphics[width=0.2\textwidth]{img/edinbr.PNG}
  \item CambR - \includegraphics[width=0.1\textwidth]{img/cambr.JPG}
  \item NottinghamR
  \item BirminghamR - \includegraphics[width=0.1\textwidth]{img/birminghamr.JPG}
  \item Oxford RUG - \includegraphics[width=0.1\textwidth]{img/oxfordrug.PNG}
  \item Bristol Data Scientists - \includegraphics[width=0.2\textwidth]{img/bristolds.JPG}
\end{itemize}
\end{frame}

\begin{frame} {International User Communities}
  \begin{itemize}

    \item International R User Conference (useR!) \\
    \includegraphics[width=0.2\textwidth]{img/userconf.PNG}

    \item Enterprise Application of the R Language (EARL) \\
    \includegraphics[width=0.2\textwidth]{img/earlconf.PNG}

    \item European R User Meeting (ERUM) \\
    \includegraphics[width=0.2\textwidth]{img/erumconf.JPG}

  \end{itemize}
\end{frame}



\begin{frame}[shrink]{Domain-specific Communities}
  \begin{itemize}
    \item R in Insurance - \includegraphics[width=0.2\textwidth]{img/rinsurance.PNG}
    \item Applied Finance with R - \includegraphics[width=0.2\textwidth]{img/rfinance.PNG}
    \item R/Pharma - \includegraphics[width=0.2\textwidth]{img/rpharma.PNG}
    \item R/Medicine - \includegraphics[width=0.2\textwidth]{img/rmedicine.PNG}
    \item NHS-R - \includegraphics[width=0.2\textwidth]{img/nhsr.PNG}
    \item R-ladies - \includegraphics[width=0.1\textwidth]{img/rladies.PNG}
    
  \end{itemize}
\end{frame}

\section{Data Transformation}


\begin{frame}{Tidyverse}
\begin{itemize}
  \item A coherent system of packages for data manipulation, exploration and visualisation.
  \item Typical workflow of a project:
\end{itemize}

    \begin{tikzpicture}[node distance = 2.5cm, auto]
        \node [block3, dashed, label={above left:\tiny Program}] (bigbox){
            \begin{tikzpicture}[node distance = 2.5cm, auto, solid]
              \node [block1] (import) {Import};
              \node [block1, right of=import] (tidy) {Tidy};
              \node [block3, dashed, fill=gray!10, below of=tidy, label={above left:\tiny Understand}] (mybox){
                  \begin{tikzpicture}[node distance = 2.5cm, auto, solid]
                      \node [block2] (transform) {Transform};
                      \node [block2, right of=transform] (visualise) {Visualise};
                      \node [block2, below of=visualise] (model) {Model};
                      \draw [arrow] (transform) -- (visualise);
                      \draw [arrow] (visualise) -- (model);
                      \draw [arrow] (model) -| (transform);
                      \draw [arrow] (visualise) -- (transform);
                      \draw [arrow] (model) -- (visualise);
                      \draw [arrow] (transform) |- (model);
                  \end{tikzpicture}
              };
              \node [block1, below of=mybox] (communicate) {Communicate};
              \draw [arrow] (import) -- (tidy);
              \draw [arrow] (tidy) -- (mybox);
              \draw [arrow] (mybox) -- (communicate);
            \end{tikzpicture}
        };
    \end{tikzpicture}
    
\end{frame}


\begin{frame}[shrink, fragile]{Tidyverse: Packages}

\begin{description}
  \item[Import] Reading datasets from various data sources.
    \begin{itemize}
      \item \verb|readr|
      \item \verb|readxl| 
      \item \verb|haven| 
      \item \verb|httr| 
      \item \verb|rvest|
      \item \verb|xml2|
    \end{itemize}
  \item[Tidy] Clean up datasets.
    \begin{itemize}
      \item \verb|tibble|
      \item \verb|tidyr|
    \end{itemize}
  \item[Transform] Aggregate, change variable format and derive new variables.
    \begin{itemize}
      \item \verb|dplyr|
      \item \verb|forcats| 
      \item \verb|hms| 
      \item \verb|lubridate| 
      \item \verb|stringr|
    \end{itemize}
  \item[Visualise] Creating charts using the Grammar of Graphics.
    \begin{itemize}
      \item \verb|ggplot2|
    \end{itemize}
  \item[Model] Train and test statistical models.
    \begin{itemize}
      \item \verb|broom|
      \item \verb|modelr|
    \end{itemize}
  \item[Program] Coding in pipeline-style.
    \begin{itemize}
      \item \verb|magrittr|
      \item \verb|purrr|
    \end{itemize}
\end{description}
\end{frame}

\begin{frame}[fragile,shrink]{Data Transformation}
\begin{itemize}
  \item Subset the observations by condition - \verb|filter()|
  \item Reorder the observations - \verb|arrange()|
  \item Pick variables by name - \verb|select()|
  \item Compute new variable as a function of existing variables - \verb|mutate()|
  \item Aggregate many values into one - \verb|summarise()| or \verb|summarize()|
  \item All of the above functions can be used with \verb|group_by()|
  \item Syntax: \verb|function(data, actions_to_take)|
\end{itemize}
\end{frame}


\begin{frame}[fragile,shrink]{Loading Dataset}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Load the package
library(nycflights13)
# View the flights dataset interactively
View(flights)
# Print out the dataset on the console
flights
@
\end{frame}


\begin{frame}[fragile,shrink]{dplyr Query}
\begin{itemize}
  \item Finding average arrival delay time for each route and sort it.
        (i.e. which route are delayed the most?)
\end{itemize}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
library(dplyr)
flights %>%
  group_by(tailnum) %>%
  summarise(delay = mean(arr_delay),
            n = n()) %>%
  arrange(desc(delay)) %>%
  filter(n > 100)
@
\end{frame}

\begin{frame}[fragile]{Filtering Observations}
\begin{itemize}
  \item Pick a subset of observations based on their values
  \item Use logical operators: \verb|>|, \verb|>=|, \verb|<|, \verb|<=|, \verb|!=|, \verb|==|
  \item More complex combinations of logical operators:
    \includegraphics[width=0.7\textwidth]{img/venn.PNG}
  \item Only returns observations where the condition is \verb|TRUE|. All \verb|FALSE| and \verb|NA| values are excluded.
  \item Use the function \verb|is.na()| to check if the value is missing.
\end{itemize}
\end{frame}

\begin{frame}[fragile,shrink]{Examples - filter()}
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Select all flights on January 1st
# Assigning them to a new variable jan1
jan1 <- filter(flights, month == 1, day == 1)
jan1
# Select all flights from November or December 
filter(flights, month == 11 | month == 12)
# A useful shorthand for this problem is x %in% y
# It selects every row where x is one of the values in y
filter(flights, month %in% c(11, 12))
# Let’s select only the flights that weren’t delayed
# (on arrival or departure) by more than two hours:
filter(flights, arr_delay <= 120, dep_delay <= 120)
@
\end{frame}


\begin{frame}[fragile]{Arranging Observations}
\begin{itemize}
  \item Changes the order of observations in a dataset.
  \item Sorts the observations by a set of variables in ascending order
  \begin{itemize}
    \item Use \verb|desc()| to sort in descending order
    \item If more than one variable is supplied, each additional variable will break ties in the values of the preceding variable.
    \item \verb|NA| values are placed at the end
  \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}[fragile,shrink]{Examples - arrange()}
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Arrange flights by year, then month, then day
arrange(flights, year, month, day)
# Use desc() to reorder by a column in descending order
arrange(flights, desc(arr_delay))
# Missing values are always sorted at the end:
df <- tibble(x = c(5, 2, NA))
arrange(df, x)
arrange(df,desc(x))
@
\end{frame}


\begin{frame}[fragile]{Selecting Variables}
\begin{itemize}
  \item Returns specific variables in the dataset, dropping the others.
  \item Comes with a number of helper functions you can use within \verb|select()| to pick out variables based on their names:
  \begin{enumerate}
    \item \verb|starts_with("abc")| matches variable names that begin with \verb|"abc"|.
    \item \verb|ends_with("xyz")| matches variable names that end with \verb|"xyz"|.
    \item \verb|contains("ijk")| matches variable names that contain \verb|"ijk"|.
    \item \verb|num_range("x", 1:3)| matches \verb|x1|, \verb|x2|, and \verb|x3|.
  \end{enumerate}
  \item Can be used to rename variables, but better to use the \verb|rename()| function
  \item To move several variables to the start of a data frame use \verb|select()| in conjunction with \verb|everything()|
\end{itemize}
\end{frame}


\begin{frame}[fragile,shrink]{Examples - select()}
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Select columns by name
select(flights, year, month, day)
# Select all columns between ‘year’ and ‘day’ (inclusive)
select(flights, year:day)
# Select all columns except those from year to day (inclusive)
select(flights, -(year:day))
# Rename a variable using rename()
rename(flights, tail_num = talinum)
# Reorder columns using the everything() helper
select(flights, time_hour, air_time, everything())
@
\end{frame}


\begin{frame}[fragile]{Compute New Variables}
\begin{itemize}
  \item Create new variables which are functions of existing ones
  \item New variables are always added at the end of the dataset
  \item To keep only the newly-computed variables and remove the old ones, use \verb|transmute()|.
  \item Many functions can be used with \verb|mutate()| to create new variables:
  \begin{description}
    \item [Arithmetic operators] \verb|+|, \verb|-|, \verb|*|, \verb|/|, \verb|^|
    \item [Modular arithmetic] \verb|%/%| for integer division and \verb|%%| for modulo
    \item [Logs] Very useful for data ranging across multiple orders of magnitude
    \item [Comparison] \verb|<|, \verb|<=|, \verb|>|, \verb|>=|, \verb|!=|, \verb|==|
    \item [Ranking] There are several of these, the most common one is \verb|min_rank()|
  \end{description}
\end{itemize}
\end{frame}


\begin{frame}[fragile,shrink]{Examples - summarise()}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
mySummary <- flights %>%
  group_by(dest) %>%
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)) %>%
  filter(count > 20)
mySummary
@
\end{frame}



\begin{frame}[fragile]{Grouped Summaries}
\begin{itemize}
  \item \verb|summarise()| and \verb|summarize()| aggregates a set of values into one.
  \item Commonly used with \verb|group_by()| to analyse properties of individual groups.
  \item Examples of summary functions:
  \begin{description}
    \item [Measures of location] Arithmetic average \verb|mean()| and median \verb|median()|.
    \item [Measures of spread] Standard deviation \verb|sd()| and interquartile range \verb|IQR()|.
    \item [Measures of rank] Minimum value \verb|min()|, maximum value \verb|max()| as well as the quantiles \verb|quantile()|
    \item [Measures of position] \verb|first()|  and \verb|last()|
  \end{description}
  \item Use the pipe operator \verb|%>%| to combining several operations
\end{itemize}
\end{frame}


\begin{frame}[fragile,shrink]{Examples - mutate()}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Select several columns only
flights_sml <- select(flights,
                      year:day,
                      ends_with("delay"),
                      distance,
                      air_time)
# Use these the smaller data frame derive new columns
mutate(flights_sml,
  	gain = arr_delay - dep_delay,
  	speed = distance / air_time * 60)
@
\end{frame}


\section{Regression Models}
\subsection{Linear Regression}

\begin{frame}{Simple Regression}
Univariate linear regression model 
\[ \hat{y}_i=\beta_0+\beta_1 x_i \]
\begin{itemize}
  \item Analogous to a straight line \( y=mx+c\)
  \item Can be chained with \(M\) dependent variables (Multivariate)
    \[ \hat{y}_i=\beta_0 + \sum_{m=1}^{M}\beta_m x_{m,i} \]
  \item Residual term \( \epsilon_i = y_i - \hat{y}_i \) assumed to be Gaussian 
    \[\epsilon_i\sim\mathcal{N}(0,\sigma^2) \]
  \item Also known as ordinary least squared (OLS) regression
\end{itemize}
% \vskip 1cm
% \begin{block}{Examples}
% Some examples of commonly used commands and features are included, to help you get started.
% \end{block}
\end{frame}

\begin{frame}[fragile,shrink]{Linear Regression in R}
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Build a univariate linear model
# These two lines are equivalent
myModel1 <- lm(mpg ~ wt, mtcars)
myModel1 <- lm(formula = mpg ~ wt, data = mtcars)
# Read the model summary
summary(myModel1)
@
\end{frame}


\begin{frame}[fragile]{More Linear Regression Models}

\begin{description}
\item [Multivariate linear model] Additional independent variables can be chained using the \verb|+| symbol. Categorical variables can be encoded as dummy on-the-fly using \verb|factor()|.
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myModel2 <- lm(mpg ~ wt + hp + qsec + factor(am), mtcars)
@

\item [Polynomial term] Model can become more flexible when an independent variable is converted into polynomial terms. Use the \verb|poly()| function.
<<fig.show='hide', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myModel3 <- lm(mpg ~ wt + qsec + factor(am) + 
                 poly(hp, 3), mtcars)
@

\item [Interaction term] Two variables can be combined to create synergy effect. The \verb|*| symbol is used to combine variables together.
<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myModel4 <- lm(mpg ~ wt * hp + qsec + factor(am), mtcars)
@
\end{description}
\end{frame}

\begin{frame}{Regression Diagnostics}
\begin{description}
  \item [Residuals vs Fitted]
  Checks for non-linear relationship. Look for a near horizontal line.

  \item [Normal Quantile-Quantile]
  It aligns model residuals against a theoretical normal distribution. If the residuals spread along a straight diagonal line on the Q-Q plot, it suggests that the residuals are normally distributed.
		
  \item [Scale-Location]
  Checks for homoscedasticity and heteroscedasticity. It is homoscedastic if observations scatter without any observable pattern.
  
  \item [Residual vs Leverage (Cook's Distance)]
  Identifies observations having strong influence to the model.
\end{description}
\end{frame}

\begin{frame}[fragile,shrink]{Diagnostics Plots}
<<fig.show='asis', eval=TRUE,echo=FALSE,results=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
par(mfrow = c(2,2))
plot(myModel3)
par(mfrow = c(1,1))
@
\end{frame}


\begin{frame}{Overfitting}
\begin{itemize}
  \item Flexible models are prone to overfitting.
  \item Overfitting makes the model less generalisable.
  \item Solution
  \begin{itemize}
    \item Use less flexible methods.
    \item Impose regularisation.
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile, shrink]{Overfitting: Visual Explaination}
	\centering\[\hat{y} = \beta_0 + \sum\limits_{j=1}^{8} {\beta_{wt}}_j x_{wt}^j + \sum\limits_{k=1}^{5} {\beta_{hp}}_k x_{hp}^k \]
<<fig.show='asis', eval=TRUE,echo=FALSE,results=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
  J <- 8
  K <- 5
  myModel4 <- lm(mpg ~ poly(wt,J) + poly(hp,K), mtcars)
  wt_along <- seq(min(mtcars$wt), max(mtcars$wt), length.out = 50)
  hp_along <- seq(min(mtcars$hp), max(mtcars$hp), length.out = 50)
  f <- function(k1, k2, model){ z <- predict(model, data.frame(wt=k1, hp=k2 )) }
  myPrediction <- outer(wt_along, hp_along, f, model = myModel4)
  myPlane <- persp(x = wt_along, xlab = "Weight",
                   y = hp_along, ylab = "Horsepower",
                   z = myPrediction, zlab = "Miles-per-Gallon",
                   theta = 30, phi = 30, expand = 0.5, col = "lightblue")
  myPoints <- trans3d(x = mtcars$wt,
                      y = mtcars$hp,
                      z = mtcars$mpg,
                      pmat=myPlane)
  points(myPoints, col="red")
@
\end{frame}

\subsection{Poisson Regression}

\begin{frame}[fragile, shrink]{Poisson Distribution}
  \begin{itemize}
    \item Count of distinct events are drawn from Poisson distribution.
    \begin{itemize}
      \item Always positive.
      \item In most cases they are integers.
    \end{itemize}
    \item e.g. Number of people in a room, number of flights delayed per day... etc.
  \end{itemize}
  <<fig.show='asis', echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, fig.width=5, fig.height=2>>=
  library(dplyr)
  library(ggplot2)
poisson_max <- 20
tibble(density = sapply(seq(0,poisson_max,1), dpois, lambda=1), frequency=0:poisson_max, lambda=1) %>%
  union_all(tibble(density = sapply(seq(0,poisson_max,1), dpois, lambda=2), frequency=0:poisson_max, lambda=2)) %>%
  union_all(tibble(density = sapply(seq(0,poisson_max,1), dpois, lambda=3), frequency=0:poisson_max, lambda=3)) %>%
  union_all(tibble(density = sapply(seq(0,poisson_max,1), dpois, lambda=4), frequency=0:poisson_max, lambda=4)) %>%
  union_all(tibble(density = sapply(seq(0,poisson_max,1), dpois, lambda=5), frequency=0:poisson_max, lambda=5)) %>%
  union_all(tibble(density = sapply(seq(0,poisson_max,1), dpois, lambda=6), frequency=0:poisson_max, lambda=6)) %>%
  union_all(tibble(density = sapply(seq(0,poisson_max,1), dpois, lambda=7), frequency=0:poisson_max, lambda=7)) %>%
  union_all(tibble(density = sapply(seq(0,poisson_max,1), dpois, lambda=8), frequency=0:poisson_max, lambda=8)) %>%
  ggplot(aes(x=frequency, y=density, colour=factor(lambda))) +
  geom_line() + 
  labs(x="Frequency", y="Density", colour="Lambda") +
  scale_colour_brewer(palette="Set2") +
  theme_classic(base_family = "serif")
@
\end{frame}

\begin{frame}[fragile, shrink]{Testing for Poisson Distribution}
\begin{itemize}
  \item Chi-square goodness of fit test.
  \item Fits the data against theoretical Poisson distribution.
  \item Look for statistical significance.
\end{itemize}
<<fig.show='asis', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Performs the Chi-squared goodness-of-fit test.
# It checks whether the variable is drawn from a Poisson distribution.
library(vcd)
gf <- goodfit(mtcars$carb, type= "poisson", method= "ML")
# Checks the statistical p-value of the goodness-of-fit test.
# If p<=0.05 then it is safe to say that the variable is Poisson.
summary(gf)
@
\end{frame}

\begin{frame}[fragile, shrink]{Goodness of Fit Plot}
<<fig.show='asis', eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, fig.width=10, fig.height=5, size='scriptsize'>>=
# Plots the observed frequency vs theoretical Poisson distribution.
# The hanging bars should fill the space if it is perfectly Poisson.
plot(gf)
@
\end{frame}

\begin{frame}[fragile, shrink]{Poisson Regression}
<<fig.show='hide',results=TRUE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE>>=
# Build a Poisson model to predict the number of carburetors in a car.
myPoissonModel <- glm(carb ~ hp + wt + factor(am), 
                      family="poisson",
                      data=mtcars)
# Read the model summary
summary(myPoissonModel)
@
\end{frame}

\subsection{Logistic Regression}

\begin{frame}[fragile, shrink]{Binomial Distribution}

\begin{itemize}
  \item There are only two possible outcomes \( \{ Y, \neg Y \} \).
  \begin{itemize}
    \item Toss a coin (Head or tail)
    \item Taking an examination (Pass or fail)
    \item Selling a product (Sold or unsold)
  \end{itemize}
  \item Likelihood of event \(Y\) and \(\neg Y\) expressed as probablity \(P(Y) + P(\neg Y) = 1\).
  \item Logistic function squeezes real value range \(X\) into \((0,1)\) to express probablity.
    \[P(Y)=\frac{1}{1+e^{-X}}\]
  <<fig.show='asis', eval=TRUE, echo=FALSE, results=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize', fig.width=5, fig.height=2>>=
  logit_min <- -5
  logit_max <- 5
  logistic <- seq(logit_min, logit_max, 0.1)
  ggplot(mapping = aes(x=logistic,
                       y=1/(1+exp(-logistic)))) +
    geom_line()+
    labs(x="X", y="Logistic function") +
    scale_colour_brewer(palette="Set2") +
    theme_classic(base_family = "serif")
  @
  \end{itemize}
\end{frame}

\begin{frame}{Logistic Regression}
\begin{itemize}
  \item Equation for logistic regression
    \[P(Y)=\frac{1}{1+e^{-(\beta_0+\beta_1 x_1+\beta_2 x_2+...+\beta_M x_M)}}\]
  \item Coefficients \( \beta_1, \beta_2, \beta_3, ..., \beta_M  \) can be converted into odds ratios \(OR(x_1), OR(x_2), OR(x_3),...,OR(x_M)\).
    \[{OR}(x_1) = \frac{odds(x_1+1)}{odds(x_1)} = \frac{e^{\beta_0+\beta_1 (x_1+1)+\beta_2 x_2+...+\beta_M x_M}}{e^{\beta_0+\beta_1 x_1+\beta_2 x_2+...+\beta_M x_M}} = e^{\beta_1}\]
    \item \(OR(x_1)\) Represents the change in probability when \(x_1\) increases by \(1\) unit.
\end{itemize}
\end{frame}

\begin{frame}[fragile, shrink]{Training a Logistic Regression Model}

\begin{itemize}
\item Build a logistic regression model to predict the dependent variable \verb|am|. (\verb|1|=manual; \verb|0|=auto)
\end{itemize}
  <<fig.show='hide',eval=TRUE,results=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
myLogisticModel <- glm(am ~ mpg + hp + disp,
                       family="binomial",
                       data=mtcars)
summary(myLogisticModel)
@

Calculate the odds ratios for this model.
<<fig.show='hide',results=TRUE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize'>>=
# Calculate the odds-ratios by taking the exponential of the coefficients
# You may also calculate the 95% confidence interval of the odds-ratio
exp(cbind(oddsratio = myLogisticModel$coefficients,
          confint(myLogisticModel)))
@
\end{frame}

\section{Tree-based Methods}

\begin{frame}{Recursive Partitioning}
  \begin{itemize}
    \item Cut off point is denoted as \(s\).
    \item Divides data into regions (leaves) \(\mathcal{R}_1, \mathcal{R}_2, \mathcal{R}_3, ...\) recursively.
    \item Works with real values as well as categorical variables.
    \item Large tree risks overfitting
    \begin{itemize}
      \item Removes weaker leaves.
      \item Regularisation.
    \end{itemize}
  \end{itemize}
  \includegraphics[width=\textwidth]{img/rpart.PNG}
\end{frame}

\subsection{Decision Tree}

\begin{frame}[fragile]{Decision Tree}
\begin{itemize}
  \item Trees can be trained with a formula and optional control parameters.
\end{itemize}
<<fig.show='none', results=FALSE, eval=TRUE, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE>>=
# Load the rpart package for recursive partitioning
library(rpart)
# Build a decision tree to predict mpg
myTree <- rpart(formula = mpg ~ wt + hp +
                  factor(carb) + 
                  factor(am), 
                data = mtcars,
                control = rpart.control(minsplit=5))
# Read the detailed summary of the tree
summary(myTree)
@
\end{frame}

\begin{frame}[fragile, shrink]{Decision Tree: Visualisation}
<<fig.show='asis', results=FALSE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE,fig.width=8, fig.height=4>>=
# Load the rpart.plot package for tree visualisation
library(rpart.plot)
rpart.plot(myTree)
@
\end{frame}

\begin{frame}[fragile, shrink]{Tree Pruning}
<<fig.show='asis', results=TRUE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE,fig.width=8, fig.height=4>>=
printcp(myTree)
plotcp(myTree)
@
\end{frame}

\subsection{Random Forest}


\begin{frame}{Random Forest}
\begin{itemize}
  \item Consists of many decision trees
  \begin{itemize}
    \item Randomly selected variables will be used in each split
    \item Usually no need to prune them (all trees are allowed to grow big)
  \end{itemize}
  \item \(M\) trees in a random forest produces \(M\) predictions
  \begin{itemize}
    \item Final prediction is calculated as mean value for regression problem
    \item Classification problem will use most the common label (majority voting)
  \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}[fragile, shrink]{Training a Random Forest}
<<fig.show='none', results=FALSE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE,fig.width=8, fig.height=4>>=
library(randomForest)
library(dplyr)
# Build a random forest with 1000 trees
# Each tree has 2 randomly selected variables
# You can change the parameters
myForest <- randomForest(mpg ~ wt + hp + carb + am, 
                         ntree = 1000,
                         mtry = 2,
                         data = mtcars %>% mutate(carb = factor(carb), 
                                                  am = factor(am)))
# Plot the error as the forest expands
plot(myForest)
@
\end{frame}

\section{Neural Networks}
\subsection{Multilayer Perceptron}

\begin{frame} [shrink] {Artificial Neurons}
\begin{itemize}
  \item Inspired by neurons in biological brain.
  \item McCulloch and Pitts described neuron as a logical process.
  \begin{itemize}
    \item Neuron takes several inputs \(\{ x_1, x_2, x_3,..., x_M \}\)
    \item Fires (activates) if the combined weighted input \( \sum_{m=1}^M w_m x_m \) exceeds threshold.
    \item Output can either be fire \(1\) or not fire \(0\).
  \end{itemize}
  \item Rosenblatt's Mark I Perceptron
  \includegraphics[width=0.45\textwidth]{img/perceptron.jpg}%
  \includegraphics[width=0.25\textwidth]{img/perceptron2.jpg}
\end{itemize}
\end{frame}

\begin{frame} {Modern Neural Networks}
\begin{itemize}
  \item Neural nets are based on non-linear processing power.
  \item Trained via gradient descent optimisers (backpropagation).
  \begin{itemize}
    \item Network initialise randomly.
    \item Requires differentiable loss function.
    \item Requires strong gradient in order to improve.
    \item Model weights improve iteratively.
    \item Converge at local minimum.
  \end{itemize}
  \item Neurons can be stacked as layers.
  \begin{itemize}
    \item Can either be shallow (\(1\) layer) or deep (many layers).
    \item State-of-the art neural networks have highly bespoke topologies.
  \end{itemize}
\end{itemize}
\end{frame}


\begin{frame} [shrink] {Activation}
\begin{itemize}
  \item Weighted inputs are combined linearly.
    \[ X = \sum_{m=1}^M w_m x_m \]
  \item Non-linear activation functions
    \begin{itemize}
      \item Sigmoid
      \item Hyperbolic tangent
      \item etc...
    \end{itemize}
<<fig.show='asis', echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, fig.width=10, fig.height=4>>=
range <- seq(-3,3,0.05)

func_sigmoid <- 1/(1+exp(-range))
func_tanh <-tanh(range)
func_softplus <- log(1+exp(range))
func_relu <- sapply(range, max, 0)

tibble(func="Sigmoid", value= func_sigmoid, range = range) %>%
  union_all(tibble(func="Hyperbolic tangent", value= func_tanh, range = range)) %>%
  union_all(tibble(func="Softplus", value= func_softplus, range = range)) %>%
  union_all(tibble(func="ReLU", value= func_relu, range = range)) %>%
  union_all(tibble(func="Linear", value= range, range = range)) %>%
  ggplot(aes(x=range, y=value, colour=func)) +
  geom_line() +
  scale_colour_brewer(palette="Set2") +
  theme_classic(base_family = "serif") + 
  theme(legend.position = "right") +
  labs(x="x", y="f(x)", colour="Activation Function")
@
\end{itemize}
\end{frame}

\begin{frame}[fragile, shrink]{Multilayer Perceptron: Topology}
\begin{itemize}
\item Layers are fully-interconnected.
\item Usually having two or more layers.
\end{itemize}
<<fig.show='asis', eval=TRUE, results='hide',echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize', fig.width=7, fig.height=5,cache=TRUE>>=
library(dplyr)
library(neuralnet)
mtcars_numeric <- mtcars[,c("mpg", "disp", "hp", "drat", "wt", "qsec")]
mtcars_mean <- mtcars_numeric %>% lapply(mean)
mtcars_sd <- mtcars_numeric %>% lapply(sd)
mtcars_numeric_normalised <- (mtcars_numeric - mtcars_mean) / mtcars_sd
myNN1 <- neuralnet(formula = mpg ~ disp + hp + drat + wt + qsec,
                   data = mtcars_numeric_normalised,
                   hidden = c(4,3),
                   linear.output = TRUE,
                   lifesign = "full")
plot(myNN1, rep = "best")
@
\end{frame}


\section{Time Series Analysis}
\subsection{Auto-Correlation Function}

\begin{frame} [shrink] {Time Series Data}
\begin{itemize}
  \item Observations repeatedly taken at regular interval.
  \item Explore variable relationship across temporal space.
  \begin{description}
    \item [Auto-correlation Function (ACF)] 
    Measures the correlation of a single variable along the temporal dimension between \(x_t\) and \(x_{t+h}\). It shows the correlation of the variable over different lag periods. For most time series variables, correlation is usually strong at lag \(h=1\) and it gradually diminishes as lag period increases. Cyclic pattern in the correlogram suggests possible seasonality which you can analyse further.
 
    \item [Partial Auto-correlation Function (PACF)]
    Also measures the correlation between different lag periods, but it controls the correlation across the temporal dimsnion so that only the contribution of an individual lag is reflected.
    
    \item [Cross Correlation Function (CCF)] Analyses the temporal correlation between two variables.
  \end{description}
\end{itemize}
\end{frame}

\begin{frame} [fragile] {ACF and PACF Correlograms}
<<fig.show='hide', eval=TRUE, results='hide', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize', cache=TRUE>>=
amprion <- read.csv("amprion.csv",
                    colClasses = c("character",
                                   "numeric",
                                   "numeric",
                                   "numeric")) %>% as_tibble()
bremen <- read.csv("bremen.csv",
                   colClasses = c("character",
                                  "numeric",
                                  "numeric",
                                  "numeric",
                                  "factor",
                                  "numeric",
                                  "numeric",
                                  "numeric",
                                  "numeric")) %>% as_tibble()
library(lubridate)
library(dplyr)
amprion_daily <- amprion %>%
                  mutate(date = datetime %>%
                           ymd_hms() %>%
                           floor_date("day") %>%
                           as.Date()) %>%
                  group_by(date) %>%
                  summarise(total_demand = sum(demand),
                            total_pv = sum(pv),
                            total_wp = sum(wp))
bremen_daily <- bremen %>%
                  mutate(date = datetime %>%
                           ymd_hms() %>%
                           floor_date("day") %>%
                           as.Date()) %>%
                  group_by(date) %>%
                  summarise(mean_airtemp = airtemp %>% mean(),
                            max_sun = sun %>% max(),
                            mean_windspd = windspd %>% mean(),
                            mean_soil10 = soil10 %>% mean(),
                            mean_soil20 = soil20 %>% mean(),
                            mean_soil50 = soil50 %>% mean(),
                            mean_soil100 = soil100 %>% mean())
myTable <- amprion_daily %>%
  left_join(bremen_daily, by = "date")
TEST_SET_BEGIN <- "2017-01-01"
myTrainingSet <- myTable %>% filter(date < TEST_SET_BEGIN)
myTestingSet <- myTable %>% filter(date >= TEST_SET_BEGIN)
@
<<fig.show='asis', eval=TRUE, results='hide', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize', cache=TRUE, fig.width=10, fig.height=8>>=
library(forecast)
tsdisplay(myTrainingSet$total_demand,
          points = FALSE)
@
\end{frame}

\subsection{Decomposition}

\begin{frame}{Decomposition}
\begin{itemize}
  \item Time series can be decomposed into:
  \begin{itemize}
    \item Seasonal component \( S_t \)
    \item Trend component \( T_t \)
    \item Residual component \( \epsilon_t \)
  \end{itemize}
  \item Additive time series is expressed as \(X_t=S_t+T_t+\epsilon_t\)
  \item Multiplicative time series is expressed as \(X_t=S_t \times T_t \times \epsilon_t\)
\end{itemize}
<<fig.show='asis', eval=TRUE, results='hide',echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize',cache=TRUE,fig.width=10,fig.height=5>>=
myTs <- ts(data = myTrainingSet$total_demand,
           frequency = 7)
myDecomp <- decompose(myTs,
                      type = "additive")
plot(myDecomp)
@
\end{frame}

\begin{frame}{Time Series Linear Regression Model}
  \begin{itemize}
    \item Decomposed components can be used as independent variable in linear regression:
    \[X_t = \beta_0 + \beta_{trend} T_t + \beta_{seasonal}S_t + \sum_{m=1}^{M}(\beta_m {x_m}_t) + \epsilon_t \]
    \item Components can also form interaction terms with other independent variables.
  \end{itemize}
\end{frame}

\subsection{ARIMA Model}

\begin{frame} {Auto-regressive Moving Average Model (ARMA)}
\begin{itemize}
\item \(ARMA(p,q)\) model
\[\underbrace{X_t}_\text{Observation} = 
\underbrace{ \beta_0 }_\text{intercept}+ 
\underbrace{ \sum_{i=i}^{p}(\phi_i X_{t-1}) }_\text{AR(p)} + 
\underbrace{ \sum_{i=1}^{q}(\theta_i \epsilon_{t-i}) }_\text{MA(q)} + 
\underbrace{\epsilon_t}_\text{residual}\]

\item \(ARIMA(p,d,q)\) model
  \begin{itemize}
    \item Auto-regressive Integrative Moving Average
    \item \(I(d)\) \(d^{th}\) order integration can be added.
    \begin{itemize}
    \item Integration refers to the difference from previous time step
    \item First order differencing \( I(1): X_t^{'}=X_t - X_{t-1} \)
    \item To satisfy \textbf{stationarity} requirement.
    \end{itemize}
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame} [shrink] {Stationarity}

\begin{itemize}
  \item Equal properties (mean and variance) across time. 
  \begin{itemize}
    \item Only one below is a stationary time series. 
    \item Which one is it?
  \end{itemize}
\end{itemize}
<<fig.show='asis', eval=TRUE, results='hide',echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize', fig.width=7, fig.height=5,cache=TRUE>>=
set.seed(2000)
tsLength <- 5000
ts1 <- rnorm(tsLength,0,1) %>% cumsum
ts2 <- rnorm(tsLength,0,10)
ts3 <- rnorm(tsLength,0,1) + sin((1:tsLength) / tsLength * pi * 8)
ts4 <- rnorm(tsLength,1,10) %>% cumsum
ts4 <- ts4^2

tibble(t = 1:tsLength, y=ts1, id ="Specimen 1") %>%
  union_all(tibble(t = 1:tsLength, y=ts2, id ="Specimen 2")) %>%
  union_all(tibble(t = 1:tsLength, y=ts3, id ="Specimen 3")) %>%
  union_all(tibble(t = 1:tsLength, y=ts4, id ="Specimen 4")) %>%
  ggplot(aes(x=t, y=y, colour=id)) + geom_line() + facet_wrap("id",nrow = 2,scales = "free_y") +
  scale_y_continuous(labels = NULL)+
  scale_x_continuous(labels = NULL)+
  labs(x="Time", y="Value") +
  scale_colour_brewer(palette="Set2") +
  theme_classic(base_family = "serif") +
  theme(legend.position = "none")
@
\end{frame}

\begin{frame} [fragile] {ARIMA with Seasonality (SARIMA)}
\begin{itemize}
  \item \(ARIMA(p,d,q)(P,D,Q)_m\)
  \begin{itemize}
    \item All parameter values can be automatically identified.
    \item Simple models are always preferred
    \item Intend to keep \(p+q+P+Q\) small.
  \end{itemize}
\end{itemize}
<<fig.show='asis', eval=TRUE, results='hide',echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize', fig.width=7, fig.height=4,cache=TRUE>>=
myTsModel4 <- Arima(y = myTs, 
                    xreg = myTrainingSet %>%
                            dplyr::select(mean_airtemp,
                                   mean_windspd,
                                   max_sun,
                                   mean_soil10,
                                   mean_soil20,
                                   mean_soil50,
                                   mean_soil100),
                    order = c(2,0,0),
                    seasonal = c(1,1,1))
myTsForecast4 <- forecast(myTsModel4, 
                          xreg = myTestingSet %>% 
                            dplyr::select(mean_airtemp,
                                   mean_windspd,
                                   max_sun,
                                   mean_soil10,
                                   mean_soil20,
                                   mean_soil50,
                                   mean_soil100))
plot(myTsForecast4)
@
\end{frame}

\section{Survival Analysis}

\begin{frame} {Survival Analysis}
\begin{itemize}
\item Event occuring at irregular intervals.
  \begin{itemize}
  \item e.g. Patients gets sick, machine failing... etc
  \end{itemize}
\item Also known as \textbf{time-to-event analysis} or \textbf{event history analysis}.
\end{itemize}
\end{frame}

\subsection{Kaplan-Meier Estimator}

\begin{frame} {Kaplan-Meier Estimator}
\begin{itemize}
\item It is used to measure how many subjects survives in a clinical trial since treatment began. 
\item Categorical variables only.
\end{itemize}
<<fig.show='asis', eval=TRUE, results='hide',echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize', fig.width=7, fig.height=4,cache=TRUE>>=
library(survival)
library(survminer)
mySurvFit2 <- survfit(Surv(time, status==2) ~ sex, lung %>% mutate(sex = factor(sex,levels = c(1,2), labels = c("Male","Female"))))
ggsurvplot(mySurvFit2, 
           palette = "Set2",
           conf.int = TRUE,
           risk.table = TRUE,
           risk.table.col = "strata",tables.height = 0.3,
           pval = TRUE)
@
\end{frame}

\subsection{Cox Proportional Harzard Model}

\begin{frame}[fragile, shrink]{Cox Proportional Harzard Model}
\begin{itemize}
  \item It is a regression method which can take into account categorical and numeric variables.
  \item Assumes effects are time-independent (proportional harzard assumption).
  \item Harzard function \(h_t\) is defined as:
  \[ h_t = h_{0,t} \times e^{\beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 +...+\beta_M x_M} \]
\end{itemize}


<<fig.show='hide', eval=FALSE, warning=FALSE, message=FALSE, error=FALSE, size='scriptsize', rexample=TRUE>>=
# Build a Cox model with predictor variables
myCoxModel1 <- coxph(Surv(time, status==2) ~ factor(sex) + age + 
                       ph.ecog + ph.karno + 
                       pat.karno + 
                       meal.cal + wt.loss, data = lung)
# Read the model summary
summary(myCoxModel1)
@
\end{frame}

\section{Unsupervised Learning}
\subsection{\(K\)-means Clustering}

\begin{frame}{K-means Clustering}
\begin{itemize}
\item Works with unlabelled data.
\item Arrange objects into groups (clusters)
\item Objective interpretation of results as \(K\) is arbitrarily selected.
\end{itemize}

<<fig.show='asis', echo=FALSE, eval=TRUE, results=FALSE, warning=FALSE, message=FALSE, error=FALSE, fig.width=7, fig.height=4>>=
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
library(dplyr)
km1 <- iris %>%
  dplyr::select(Sepal.Length, Sepal.Width) %>%
  kmeans(2)
clust1 <- iris %>% ggplot(aes(x= Sepal.Length, y= Sepal.Width, colour= km1$cluster %>% factor)) +
  geom_point()+
  geom_point(aes(x=Sepal.Length, y=Sepal.Width),km1$centers %>% as_tibble, shape="X",colour="black", size=6)+
  scale_colour_brewer(palette="Set2") +
  theme_classic(base_family = "serif") + 
  theme(legend.position = "none") +
  labs(x="Variable 1", y="Variable 2")

km2 <- iris %>%
  dplyr::select(Sepal.Length, Sepal.Width) %>%
  kmeans(4)
clust2 <- iris %>% ggplot(aes(x= Sepal.Length, y= Sepal.Width, colour= km2$cluster %>% factor)) +
  geom_point()+
  geom_point(aes(x=Sepal.Length, y=Sepal.Width),km2$centers %>% as_tibble, shape="X",colour="black", size=6)+
  scale_colour_brewer(palette="Set2") +
  theme_classic(base_family = "serif") + 
  theme(legend.position = "none") +
  labs(x="Variable 1", y="Variable 2")

km3 <- iris %>%
  dplyr::select(Sepal.Length, Sepal.Width) %>%
  kmeans(6)
clust3 <- iris %>% ggplot(aes(x= Sepal.Length, y= Sepal.Width, colour= km3$cluster %>% factor)) +
  geom_point()+
  geom_point(aes(x=Sepal.Length, y=Sepal.Width),km3$centers %>% as_tibble, shape="X",colour="black", size=6)+
  scale_colour_brewer(palette="Set2") +
  theme_classic(base_family = "serif") + 
  theme(legend.position = "none") +
  labs(x="Variable 1", y="Variable 2")

km4 <- iris %>%
  dplyr::select(Sepal.Length, Sepal.Width) %>%
  kmeans(8)
clust4 <- iris %>% ggplot(aes(x= Sepal.Length, y= Sepal.Width, colour= km4$cluster %>% factor)) +
  geom_point()+
  geom_point(aes(x=Sepal.Length, y=Sepal.Width),km4$centers %>% as_tibble, shape="X",colour="black", size=6)+
  scale_colour_brewer(palette="Set2") +
  theme_classic(base_family = "serif") + 
  theme(legend.position = "none") +
  labs(x="Variable 1", y="Variable 2")

multiplot(clust1, clust2, clust3, clust4,cols = 2)
@

\end{frame}

\subsection{Hierarchical Clustering}

\begin{frame}{Agglomerative Hierarchical Clustering}
\begin{itemize}
  \item \(N\) objects can form maximum \(N\) clusters, each having \(1\) member object.
  \item Identify distance between closest cluster pair.
  \item Merge them.
  \item Repeat until there are no more clusters left.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Agglomerative Hierarchical Clustering: Example}
<<fig.show="asis", echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE, error=FALSE, fig.width=14, fig.height=8>>=
StatChull <- ggproto("StatChull", Stat,
  compute_group = function(data, scales) {
    data[chull(data$x, data$y), , drop = FALSE]
  },
  
  required_aes = c("x", "y")
)
stat_chull <- function(mapping = NULL, data = NULL, geom = "polygon",
                       position = "identity", na.rm = FALSE, show.legend = NA, 
                       inherit.aes = TRUE, ...) {
  layer(
    stat = StatChull, data = data, mapping = mapping, geom = geom, 
    position = position, show.legend = show.legend, inherit.aes = inherit.aes,
    params = list(na.rm = na.rm, ...)
  )
}
myDist <- mtcars[,c("disp","qsec")] %>% scale %>% dist()
hc <- myDist %>% hclust()
getHPlot <- function(i){
  ggplot(mtcars, aes(x=disp, y=qsec, group=factor(cutree(hc, k=i)))) +
  geom_point(size=0.5) +
  stat_chull(fill = NA, colour = "red", size=1) +
  #geom_text(aes(x=250, y=22,label=)) +
  scale_colour_brewer(palette="Set2") +
  theme_classic(base_family = "serif") + 
  theme(legend.position = "bottom") +
  labs(x=paste0("Iteration ", nrow(mtcars)-i+1 ), y=NULL) +
  scale_x_continuous(labels = NULL) + 
  scale_y_continuous(labels = NULL)
}
plt <- lapply(32:1, getHPlot)
multiplot(plotlist = plt, cols = 8)
@
\end{frame}

\section{Extending R}

\begin{frame}[fragile]{R Markdown}
  \begin{itemize}
    \item Generate documents and reports easily
    \item Has special file extension \verb|.Rmd| 
    \item Contains three types of content:
    \item
    \begin{description}
      \item[YAML header] Surrounded by \verb|---| at the top of the document. Users can specify key parameters here, such as output format, 
      \item[Text] Standard Markdown format.
      \item[Code chunk] Surrounded by \verb|```|, optional arguments can be provided in the trailing curly bracket \verb|{}|.
    \end{description}
    \item Can be converted to output through \textbf{Knit}.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{R Notebook}
  \begin{itemize}
    \item Similar to R Markdown.
    \item Only difference is \verb|output: html_notebook|.
    \item Conde chunks can execute independently and interactively.
    \item It renders through \textbf{Preview} rather than \textbf{Knit}.
    \item Good way to document workflow.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Shiny Web Application}
  \begin{itemize}
    \item Interactive web applications
    \item Non-technical users can access analytics in real-time
    \item All written in \verb|R| - no \verb|HTML|, \verb|CSS|, \verb|JavaScript|.
    \item Shiny has two main components:
    \item
    \begin{description}
      \item [ui] This defines the user interface (UI) for the \verb|shiny| application, e.g. the page layout, location of control widgets, page title, etc.
      \item [server] The server-side application which contains the logic. The analytical code is located in this part.
    \end{description}
  \end{itemize}
\end{frame}

\begin{frame}{Shiny App Example}
  \begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/shiny.PNG}
  \end{figure}
\end{frame}

\begin{frame}{Control Widgets}
  \begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/shiny-inputs.PNG}
  \end{figure}
\end{frame}

\begin{frame}[fragile]{Writing Package}
  \begin{itemize}
    \item Functions are wrapped in packages.
    \item Can be reused and transported.
    \item Standardised \verb|R| documentation.
  \end{itemize}
\end{frame}

\begin{frame}{Create a New Package}
  \begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/package-create.png}
  \end{figure}
\end{frame}

\begin{frame}[shrink, fragile]{Roxygen2-style documentation}
<<eval=FALSE, size='scriptsize', rexample=TRUE>>=
#' Checks even number
#'
#' \code{is_even()} returns \code{TRUE} if the input is an even number.
#'
#' @author James Bond \email{jbond@@universialexports.com}
#'
#' @param x Input integer vector.
#' @return Logical vector
#'
#' @examples
#' myNumbers <- 1:20
#' is_even(myNumbers)
#'
#' @export
is_even <- function(x) {
if(!is.integer(x)){
stop("Input is not integer")
}
return (x %% 2) == 0
}
@
\end{frame}

\section{Efficient Programming}

\begin{frame}[fragile]{Memory Usage}
  \begin{itemize}
    \item All real numbers are stored as double-precision values.
    \item Size of object grows \textit{almost} proportionally with vector length.
    \item The package \verb|pryr| can be used to track memory usage.
  \end{itemize}
\end{frame}

\begin{frame}[fragile, shrink]{Object Size}
<<eval=TRUE,message=FALSE,warning=FALSE, error=FALSE, size='scriptsize', rexample=TRUE>>=
library(pryr)
# Displays the size of an integer value 
# Note the trailing 'L' character, this forces the number to become an integer
object_size(3L)
# Significant figure of a numeric valule has no effect on object size
# Therefore these two values have the same object size
object_size(3.14)
object_size(3.14159265359)
# Creates an integer vector
# This contains 1 million integers
# Consumes 4 MB memory
myBigVec1 <- 1:1e6
object_size(myBigVec1)
@
\end{frame}


\begin{frame}[fragile, shrink]{Object Size}
<<eval=TRUE, message=FALSE, error=FALSE, size='scriptsize', rexample=TRUE>>=
# Both character objects have identical object size.
# Each consume 120 bytes.
object_size("My name is Bond.")
object_size("My name is Bond, James Bond.")
@
\end{frame}

\begin{frame}[fragile, shrink]{Memory Use}
  \begin{itemize}
    \item Using the correct data type can save memory.
    \item Object size of logical value is much smaller than character value.
    \item In this case, the character vector is three time larger.
  \end{itemize}
<<eval=TRUE, message=FALSE, error=FALSE>>=
object_size(c("Yes", "No", "No", "Yes"))
object_size(c(TRUE, FALSE, FALSE, TRUE))
@
\end{frame}


\begin{frame}[fragile, shrink]{Tracking Memory Change}
  \begin{itemize}
    \item Track memory used by objects using \verb|mem_used()|
  \end{itemize}
<<eval=TRUE, message=FALSE, error=FALSE, size='scriptsize', rexample=TRUE>>=
# Returns the total memory used by all R objects
mem_used()
# Assign a large vector
# This will consume memory (+4 MB)
mem_change({ myBigVec2 <- 1:1e6 })
# Remove a large vector
# This releases memory (-4 MB)
mem_change({ rm(myBigVec2) })
@
\end{frame}

\begin{frame}[fragile, shrink]{Memory Profiling}
  \begin{itemize}
    \item Memory profile can be used to identify process bottleneck.
    \item Package \verb|profvis| can help.
  \end{itemize}
<<eval=FALSE,message=FALSE,warning=FALSE, error=FALSE, size='scriptsize', rexample=TRUE>>=
library(profvis)
profvis({
# Generate some random numbers from normal distribution
myDataX <- rnorm(1e6)
myDataY <- rnorm(1e6)
# Run a linear model
myModel <- lm(myDataY ~ myDataX)
# View the model summary
summary(myModel)
})
@
\end{frame}

\begin{frame}[shrink]{Flame Graph}
  \begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{img/profvis.png}
  \end{figure}
\end{frame}

\begin{frame}[fragile]{Multithreaded Processing}
  \begin{itemize}
    \item \verb|R| was historically designed to run in a single thread.
    \item Parallelism has to be explicitly called.
    \item Microsoft R Open (MRO) extends \verb|R| by using Intel Math Kernel Library (MKL) for BLAS/LAPACK operations. This enables multithreaded math operations.
    \item For custom \verb|R| code, users can access CPU cores using the package \verb|parallel|.
  \end{itemize}
\end{frame}

\begin{frame}[fragile, shrink]{Setting MKL Threads}
<<eval=FALSE,message=FALSE,warning=FALSE, error=FALSE, size='scriptsize', rexample=TRUE>>=
# Detects how many threads are in use
getMKLthreads()
# Change to 4 threads
setMKLthreads(4)
# Reset to system default value
setMKLthreads()
@
\end{frame}

\begin{frame}[fragile, shrink]{Multithreaded R Code}
  <<eval=TRUE,message=FALSE,warning=FALSE, error=FALSE, size='scriptsize', rexample=TRUE>>=
# Standard apply family
system.time({
  sapply(1:10, function(x) {Sys.sleep(0.25)})
})

# Parallel apply
library(parallel)
system.time({
  # Detect how many cores are available on the system
  myCores <- detectCores()
  # Create a parallel cluster
  # Use 25% of system cores
  myCluster <- makeCluster(floor(myCores * 1/4))
  # Run the same process on multicore
  parSapply(myCluster, 1:10, function(x) {Sys.sleep(0.25)})
  # Stop the cluster
  stopCluster(myCluster)
})
@
\end{frame}

\section{Distributed Computing}

\begin{frame}{Big Data Processing}
  \begin{itemize}
    \item Large datasets cannot fit in memory
    \item There are several solutions:
    \begin{itemize}
      \item Store the dataset on hard drive instead, and process by smaller chunk (Only load the smaller chunks into memory).
      \item Distribute the workload on a large cluster.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile, shrink]{Apache Spark}
\begin{description}

  \item [Standalone] This is also known as local mode. The driver and executors run on the client machine. Although there is no distribution of computing process, prototyping and debugging in local mode is more convinient.
  
  <<eval=FALSE, size='scriptsize',rexample=TRUE>>=
  library(sparklyr)
  library(dplyr)
  # Opens the Spark connection through sparklyr
  # Using standalone mode (local master)
  mySparkConn <- spark_connect(master = "local")
  # Checks whether the connection is opened
  mySparkConn %>% connection_is_open()
  # Checks Spark version
  mySparkConn %>% spark_version()
  @

  \item [YARN Client]
  Spark driver is launched in the same process as the client that submits the application. Resource allocation is done by YARN Resource Manager (RM) based on data locality. Driver program on client machine controls the executors on YARN cluster.
  
  \item [YARN Cluster] The Spark client submits an application to the YARN cluster. Both the driver and executors run on the YARN cluster.
  
\end{description}
\end{frame}

\begin{frame}[fragile, shrink]{Spark MLlib in R}
<<ex:sparkdplyr, eval=FALSE, size='scriptsize',rexample=TRUE>>=
library(sparklyr)
library(dplyr)
library(nycflights13)
mySparkConn <- spark_connect(master = "local")
# Converts an R object into Spark DataFrame
flights_tbl <- mySparkConn %>% copy_to(flights)
# Runs dplyr pipeline on Spark
# It returns a Spark DataFrame
myFlightsSummary <- flights_tbl %>%
  group_by(year, month) %>%
  summarise(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) %>%
  arrange(year, month)
  # Print it out on the console
myFlightsSummary
@
\end{frame}

\begin{frame}[fragile]{Microsoft Machine Learning Server (MLS)}
  \begin{itemize}
    \item Data is stored on file system
    \item Runs on multiple compute context
    \item Uses \verb|XDF| file format: compressed small chunks
  \end{itemize}
\end{frame}

\begin{frame}[fragile, shrink]{Loading Data into MLS}
<<eval=FALSE, size='scriptsize',rexample=TRUE>>=
library(nycflights13)
# Configure the compute context
# It works parallel
rxOptions(numCoresToUse = 4)
rxSetComputeContext(RxLocalParallel())
# Creates a pointer to a local XDF file
myFlightsClean <- RxXdfData("flight_clean.xdf")
# Clean the dataset by removing NA values
# Also chop it into smaller chunks
rxDataStep(inData = flights,
           outFile = myFlightsClean,
           overwrite = TRUE,
           rowsPerRead = 50000,
           removeMissings = TRUE)
# Run a simple histogram
rxHistogram(~ dep_delay_log | origin,
            myFlightsClean,
            transforms = list(dep_delay_log = log(dep_delay),
                              origin = factor(origin)))
@
\end{frame}

\end{document}
